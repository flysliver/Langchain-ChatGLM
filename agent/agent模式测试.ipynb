{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ff171c-f5f8-4590-9ce0-21c87e3d5b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO  2023-06-09 20:52:01,296-1d: \n",
      "loading model config\n",
      "llm device: cuda\n",
      "embedding device: cuda\n",
      "dir: /media/gpt4-pdf-chatbot-langchain/dev-langchain-ChatGLM\n",
      "flagging username: 35d96e513c5347dbb0c1d7c2fb21cbd4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/media/gpt4-pdf-chatbot-langchain/dev-langchain-ChatGLM/')\n",
    "from langchain.llms.base import LLM\n",
    "import torch\n",
    "import transformers \n",
    "import models.shared as shared \n",
    "from abc import ABC\n",
    "\n",
    "from langchain.llms.base import LLM\n",
    "import random\n",
    "from transformers.generation.logits_process import LogitsProcessor\n",
    "from transformers.generation.utils import LogitsProcessorList, StoppingCriteriaList\n",
    "from typing import Optional, List, Dict, Any\n",
    "from models.loader import LoaderCheckPoint \n",
    "from models.base import (BaseAnswer,\n",
    "                         AnswerResult)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68978c38-c0e9-4ae9-ba90-9c02aca335be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vicuna-13b-hf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
      "/media/gpt4-pdf-chatbot-langchain/pyenv-langchain/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /media/gpt4-pdf-chatbot-langchain/pyenv-langchain did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /media/gpt4-pdf-chatbot-langchain/pyenv-langchain/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA SETUP: CUDA runtime path found: /opt/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /media/gpt4-pdf-chatbot-langchain/pyenv-langchain/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df1856e06d1460683851a0b73537a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the model in 11.22 seconds.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from argparse import Namespace\n",
    "from models.loader.args import parser\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    " \n",
    "args = parser.parse_args(args=['--model', 'vicuna-13b-hf', '--no-remote-model', '--load-in-8bit'])\n",
    "\n",
    "args_dict = vars(args)\n",
    "\n",
    "shared.loaderCheckPoint = LoaderCheckPoint(args_dict)\n",
    "torch.cuda.empty_cache()\n",
    "llm=shared.loaderLLM() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e4a58d-1a3a-484a-8417-bcec0eb7170e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'summary', 'action_input': '露ᥫᩣ,'}\n"
     ]
    }
   ],
   "source": [
    "from jsonformer import Jsonformer\n",
    "json_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"action\": {\"type\": \"string\"},\n",
    "        \"action_input\": {\"type\": \"string\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "prompt = \"\"\" Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
    "\n",
    "State of Dialogue History System: 露ᥫᩣ, 张毛峰的对话 - 当需要查找露ᥫᩣ, 张毛峰之间的聊天内容时，这里面的回答是很有用的。输入应该是一个完整的问题。\n",
    "Summary: useful for when you summarize a conversation. The input to this tool should be a string, representing who will read this summary.\n",
    "\n",
    "The way you use the tools is by specifying a json blob.\n",
    "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
    "\n",
    "The only values that should be in the \"action\" field are: {tool_names}\n",
    "\n",
    "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
    "\n",
    "```\n",
    "{{{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}}}\n",
    "```\n",
    "\n",
    "ALWAYS use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
    "\n",
    "Question: 我想查看关于露露的摘要信息\n",
    "\"\"\"\n",
    "jsonformer = Jsonformer(shared.loaderCheckPoint.model, shared.loaderCheckPoint.tokenizer, json_schema, prompt)\n",
    "generated_data = jsonformer()\n",
    "\n",
    "print(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a55f92ce-4ebf-4cb3-8e16-780c14b6517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import StructuredTool\n",
    "\n",
    "def multiplier(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply the provided floats.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tool = StructuredTool.from_function(multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e089a828-b662-4d9a-8d88-4bf95ccadbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4ea7f0e-1ba9-4f40-82ec-7c453bd64945",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Structured tools are compatible with the STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION agent type. \n",
    "agent_executor = initialize_agent([tool], llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "640bfdfb-41e7-4429-9718-8fa724de12b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "__call:System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
      "\n",
      "multiplier: multiplier(a: float, b: float) -> float - Multiply the provided floats., args: {{'a': {{'title': 'A', 'type': 'number'}}, 'b': {{'title': 'B', 'type': 'number'}}}}\n",
      "\n",
      "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
      "\n",
      "Valid \"action\" values: \"Final Answer\" or multiplier\n",
      "\n",
      "Provide only ONE action per $JSON_BLOB, as shown:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "Follow this format:\n",
      "\n",
      "Question: input question to answer\n",
      "Thought: consider previous and subsequent steps\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: action result\n",
      "... (repeat Thought/Action/Observation N times)\n",
      "Thought: I know what to respond\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Final response to human\"\n",
      "}\n",
      "```\n",
      "\n",
      "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\n",
      "Thought:\n",
      "Human: What is 1 times 14\n",
      "\n",
      "\n",
      "response:System: ```{\"action\":\"multiplier\",\"action_input\":{\"a\":1,\"b\":14}}``\n",
      "\n",
      "Observation:\n",
      "\u001b[32;1m\u001b[1;3mSystem: ```{\"action\":\"multiplier\",\"action_input\":{\"a\":1,\"b\":14}}``\n",
      "\n",
      "Observation:\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m14.0\u001b[0m\n",
      "Thought:__call:System: Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
      "\n",
      "multiplier: multiplier(a: float, b: float) -> float - Multiply the provided floats., args: {{'a': {{'title': 'A', 'type': 'number'}}, 'b': {{'title': 'B', 'type': 'number'}}}}\n",
      "\n",
      "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
      "\n",
      "Valid \"action\" values: \"Final Answer\" or multiplier\n",
      "\n",
      "Provide only ONE action per $JSON_BLOB, as shown:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "Follow this format:\n",
      "\n",
      "Question: input question to answer\n",
      "Thought: consider previous and subsequent steps\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: action result\n",
      "... (repeat Thought/Action/Observation N times)\n",
      "Thought: I know what to respond\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Final response to human\"\n",
      "}\n",
      "```\n",
      "\n",
      "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\n",
      "Thought:\n",
      "Human: What is 1 times 14\n",
      "\n",
      "This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\n",
      "System: ```{\"action\":\"multiplier\",\"action_input\":{\"a\":1,\"b\":14}}``\n",
      "\n",
      "Observation:\n",
      "Observation: 14.0\n",
      "Thought:\n",
      "response:\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"What is 1 times 14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa881f-5ff2-4958-b3a2-1653a5e8bc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
